import spacy

# Load the English language model
nlp = spacy.load("en_core_web_sm")

# Example sentences
sentences = [
    "John and Mary went to the store.",
    "The big brown dog chased the small black cat."
]

# Perform dependency parsing for each sentence
for sentence in sentences:
    # Process the text with spaCy
    doc = nlp(sentence)

    # Print the token dependencies
    print("\nSentence:", sentence)
    for token in doc:
        print(f"{token.text} --{token.dep_}--> {token.head.text}")
